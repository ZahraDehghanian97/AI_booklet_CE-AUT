{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Densenet_Vs._ResNet.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOfoD0CYjrPP6ABVYT8KF/b",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zahraDehghanian97/AI_booklet_CE-AUT/blob/master/Densenet_Vs__ResNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWheA6CSj3ft"
      },
      "source": [
        "# **Mount google drive**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "9r3444wwj6Mr",
        "outputId": "30b3e851-1b90-4ac8-e621-cb67ad0b6a1c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTSvl-QYjyo3"
      },
      "source": [
        "# **prerequisit**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3bPfRvshs1o"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from keras.layers import  Flatten, Dense, Input, Dropout \n",
        "import glob\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AqTjhr0Rj0RW"
      },
      "source": [
        "# **call back**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZmRtsodjztK"
      },
      "source": [
        "class EarlyStoppingCallback(keras.callbacks.Callback):\n",
        "  def __init__(self,patience=0):\n",
        "    super(EarlyStoppingCallback,self).__init__()\n",
        "    self.patience=patience\n",
        "    self.best=np.Inf\n",
        "    self.wait=0\n",
        "    self.stopped_epoch=0\n",
        "  def on_epoch_end(self,epoch,logs=None):\n",
        "    current_loss=logs.get(\"val_loss\")\n",
        "    if np.less(current_loss,self.best):\n",
        "      self.best=current_loss\n",
        "      self.wait=0\n",
        "      self.best_weights=self.model.get_weights()\n",
        "    else:\n",
        "      self.wait+=1\n",
        "      print(\"\\nwait mode, step: %d\"% self.wait)\n",
        "      if self.wait>=self.patience:\n",
        "        self.stopped_epoch=epoch\n",
        "        self.model.stop_training=True\n",
        "        self.model.set_weights(self.best_weights)\n",
        "        print(\"epoch: %d : early stopping.\"% self.stopped_epoch)\n",
        "        self.wait = 0\n",
        "      \n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fjMMgNOLkSzX"
      },
      "source": [
        "# **Make dataset ready**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97QoNMEWkXoZ"
      },
      "source": [
        "def load_photos(type,dir_name):\n",
        "    photo_list =[]\n",
        "    y = []\n",
        "    for file_name in (glob.glob(dir_name+'/*')):\n",
        "        img = image.load_img(file_name, target_size=input_size)\n",
        "        img = np.array(img)\n",
        "        photo_list.append(img)\n",
        "        y.append(type)\n",
        "    return photo_list , y \n",
        "  \n",
        "    \n",
        "input_size = (250,250)\n",
        "input_shape = (250,250,3)\n",
        "dir_name_indoor = \"/content/drive/MyDrive/Colab Notebooks/indoor\"\n",
        "dir_name_outdoor = \"/content/drive/MyDrive/Colab Notebooks/outdoor\"\n",
        "X1 , y1= load_photos(0,dir_name_indoor) \n",
        "X2 , y2= load_photos(1,dir_name_outdoor) \n",
        "X1.extend(X2)\n",
        "y1.extend(y2)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X1, y1, test_size=0.1, random_state=42)\n",
        "X_train = np.array(X_train)\n",
        "X_test = np.array(X_test)\n",
        "y_test = np.array(y_test)\n",
        "y_train = np.array(y_train)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yBRdjt5g5FDD"
      },
      "source": [
        "# **ResNet**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77
        },
        "id": "edhsqUClIJQ6",
        "outputId": "7394f2de-868e-43d4-a844-7c4d9948bc46"
      },
      "source": [
        "keras.backend.clear_session() \n",
        "\n",
        "base_model = keras.applications.ResNet152(include_top=False, weights=\"imagenet\",  input_shape=input_shape)\n",
        "base_model.trainable  = False\n",
        "model_res = Sequential()\n",
        "model_res.add(base_model)\n",
        "model_res.add(Flatten())\n",
        "model_res.add(Dense(1500,activation='relu'))\n",
        "model_res.add(Dropout(0.2))\n",
        "model_res.add(Dense(500,activation='relu'))\n",
        "model_res.add(Dropout(0.1))\n",
        "model_res.add(Dense(150,activation='relu'))\n",
        "model_res.add(Dense(50,activation='relu'))\n",
        "model_res.add(Dense(10,activation='relu'))\n",
        "model_res.add(Dense(2))\n",
        "tf.keras.utils.plot_model(model_res,show_shapes=True,expand_nested=True)\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "-DhO1ZV4OQOH",
        "outputId": "76abf163-3eca-446f-9252-1c41f2593ae9"
      },
      "source": [
        "model_res.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),metrics=['accuracy'])\n",
        "es_callback=EarlyStoppingCallback(patience=5)\n",
        "model_res.fit(X_train,y_train,epochs=1000,validation_split=0.2,callbacks=[es_callback])\n",
        "\n",
        "prediction_without_fine_tune_res =np.argmax(model_res.predict(X_test),axis=1)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... Layer ModuleWrapper has arguments in `__init__` and therefore must override `get_config`.\n",
            "Epoch 1/1000\n",
            "18/18 [==============================] - 444s 23s/step - loss: 2.2547 - accuracy: 0.6434 - val_loss: 0.6739 - val_accuracy: 0.5417\n",
            "Epoch 2/1000\n",
            "18/18 [==============================] - 401s 23s/step - loss: 0.6405 - accuracy: 0.6770 - val_loss: 1.4326 - val_accuracy: 0.9236\n",
            "\n",
            "wait mode, step: 1\n",
            "Epoch 3/1000\n",
            "18/18 [==============================] - 406s 23s/step - loss: 0.7101 - accuracy: 0.9520 - val_loss: 0.4788 - val_accuracy: 0.9167\n",
            "Epoch 4/1000\n",
            "18/18 [==============================] - 399s 22s/step - loss: 0.2471 - accuracy: 0.9598 - val_loss: 0.8394 - val_accuracy: 0.8194\n",
            "\n",
            "wait mode, step: 1\n",
            "Epoch 5/1000\n",
            "18/18 [==============================] - 401s 23s/step - loss: 0.2409 - accuracy: 0.8810 - val_loss: 0.3855 - val_accuracy: 0.8889\n",
            "Epoch 6/1000\n",
            "18/18 [==============================] - 398s 22s/step - loss: 0.2022 - accuracy: 0.9474 - val_loss: 2.2093 - val_accuracy: 0.9097\n",
            "\n",
            "wait mode, step: 1\n",
            "Epoch 7/1000\n",
            "18/18 [==============================] - 394s 22s/step - loss: 0.0887 - accuracy: 0.9870 - val_loss: 0.2763 - val_accuracy: 0.8958\n",
            "Epoch 8/1000\n",
            "18/18 [==============================] - 402s 23s/step - loss: 0.1833 - accuracy: 0.9255 - val_loss: 1.9778 - val_accuracy: 0.9097\n",
            "\n",
            "wait mode, step: 1\n",
            "Epoch 9/1000\n",
            "18/18 [==============================] - 395s 22s/step - loss: 0.1853 - accuracy: 0.9796 - val_loss: 0.6731 - val_accuracy: 0.8611\n",
            "\n",
            "wait mode, step: 2\n",
            "Epoch 10/1000\n",
            "18/18 [==============================] - 401s 23s/step - loss: 0.1545 - accuracy: 0.9161 - val_loss: 1.8427 - val_accuracy: 0.9306\n",
            "\n",
            "wait mode, step: 3\n",
            "Epoch 11/1000\n",
            "18/18 [==============================] - 400s 23s/step - loss: 0.1739 - accuracy: 0.9762 - val_loss: 1.9225 - val_accuracy: 0.8472\n",
            "\n",
            "wait mode, step: 4\n",
            "Epoch 12/1000\n",
            "18/18 [==============================] - 394s 22s/step - loss: 0.2854 - accuracy: 0.9608 - val_loss: 1.3099 - val_accuracy: 0.9097\n",
            "\n",
            "wait mode, step: 5\n",
            "epoch: 11 : early stopping.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9DPtqdGxwfx"
      },
      "source": [
        "## fine tune"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "N48du0zkxwHc",
        "outputId": "add34cec-ef87-4fe7-fbe7-a46e5fa19cce"
      },
      "source": [
        "layers = base_model.layers\n",
        "for layer in layers[-50:-1]:\n",
        "  layer.trainable = True\n",
        "model_res_fine=keras.models.Sequential()\n",
        "model_res_fine.add(base_model)\n",
        "for i in range(1,len(model_res.layers)):\n",
        "  model_res_fine.add(model_res.layers[i])\n",
        "model_res_fine.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001), loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),metrics=['accuracy'])\n",
        "model_res_fine.fit(X_train,y_train,epochs=1000,validation_split=0.2,callbacks=[es_callback,tb_callback])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... Layer ModuleWrapper has arguments in `__init__` and therefore must override `get_config`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "18/18 [==============================] - 416s 23s/step - loss: 0.1404 - accuracy: 0.9688 - val_loss: 0.8096 - val_accuracy: 0.9097\n",
            "\n",
            "wait mode, step: 1\n",
            "Epoch 2/1000\n",
            "18/18 [==============================] - 405s 23s/step - loss: 0.1024 - accuracy: 0.9809 - val_loss: 0.4889 - val_accuracy: 0.9097\n",
            "\n",
            "wait mode, step: 2\n",
            "Epoch 3/1000\n",
            "18/18 [==============================] - 406s 23s/step - loss: 0.0692 - accuracy: 0.9844 - val_loss: 0.8496 - val_accuracy: 0.9236\n",
            "\n",
            "wait mode, step: 3\n",
            "Epoch 4/1000\n",
            "18/18 [==============================] - 406s 23s/step - loss: 0.1083 - accuracy: 0.9792 - val_loss: 2.0366 - val_accuracy: 0.9236\n",
            "\n",
            "wait mode, step: 4\n",
            "Epoch 5/1000\n",
            "18/18 [==============================] - 401s 23s/step - loss: 0.0318 - accuracy: 0.9913 - val_loss: 1.0199 - val_accuracy: 0.9167\n",
            "\n",
            "wait mode, step: 5\n",
            "epoch: 4 : early stopping.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f8db726fa10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "NZK5-_gx17lC",
        "outputId": "e9239468-5c73-4a87-e390-53d151a8c397"
      },
      "source": [
        "prediction_fine_tune_res=np.argmax(model_res_fine.predict(X_test),axis=1)\n",
        "print(\"ResNet Result ==============================>>\")\n",
        "print('accuracy without fine tuning = '+ str(accuracy_score(y_test,prediction_without_fine_tune_res)))\n",
        "print('confusion matrix without fine tuning'+ str( confusion_matrix(y_test,prediction_without_fine_tune_res)))\n",
        "print('accuracy with fine tuning = '+ str(accuracy_score(y_test,prediction_fine_tune_res)))\n",
        "print('confusion matrix with fine tuning'+ str( confusion_matrix(y_test,prediction_fine_tune_res)))\n",
        "\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ResNet Result ==============================>>\n",
            "accuracy without fine tuning = 0.875\n",
            "confusion matrix without fine tuning[[31 10]\n",
            " [ 0 39]]\n",
            "accuracy with fine tuning = 0.875\n",
            "confusion matrix with fine tuning[[31 10]\n",
            " [ 0 39]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A1R7jCWK8lg2"
      },
      "source": [
        "# **DenseNet**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77
        },
        "id": "xBRmXnpA8lhf",
        "outputId": "223a29d6-2f9e-4277-a152-f6148a206f80"
      },
      "source": [
        "keras.backend.clear_session() \n",
        "\n",
        "base_model = keras.applications.DenseNet201(include_top=False, weights=\"imagenet\",  input_shape=input_shape)\n",
        "base_model.trainable  = False\n",
        "model_dense = Sequential()\n",
        "model_dense.add(base_model)\n",
        "model_dense.add(Flatten())\n",
        "model_dense.add(Dense(2500,activation='relu'))\n",
        "model_dense.add(Dropout(0.2))\n",
        "model_dense.add(Dense(1000,activation='relu'))\n",
        "model_dense.add(Dropout(0.1))\n",
        "model_dense.add(Dense(250,activation='relu'))\n",
        "model_dense.add(Dense(50,activation='relu'))\n",
        "model_dense.add(Dense(10,activation='relu'))\n",
        "model_dense.add(Dense(2))\n",
        "tf.keras.utils.plot_model(model_dense,show_shapes=True,expand_nested=True)\n",
        "\n",
        "\n",
        " "
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQtHFjQm8lhn",
        "outputId": "2dc35183-bc67-49bd-aaec-6ceb79797398"
      },
      "source": [
        "model_dense.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),metrics=['accuracy'])\n",
        "es_callback=EarlyStoppingCallback(patience=5)\n",
        "model_dense.fit(X_train,y_train,epochs=1000,validation_split=0.2,callbacks=[es_callback])\n",
        "\n",
        "prediction_without_fine_tune_dense =np.argmax(model_dense.predict(X_test),axis=1)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "18/18 [==============================] - 252s 12s/step - loss: 97.1027 - accuracy: 0.5136 - val_loss: 2.5230 - val_accuracy: 0.8542\n",
            "Epoch 2/1000\n",
            "18/18 [==============================] - 210s 12s/step - loss: 6.8943 - accuracy: 0.7604 - val_loss: 5.1524 - val_accuracy: 0.8264\n",
            "\n",
            "wait mode, step: 1\n",
            "Epoch 3/1000\n",
            "18/18 [==============================] - 213s 12s/step - loss: 2.7718 - accuracy: 0.8655 - val_loss: 3.5038 - val_accuracy: 0.8264\n",
            "\n",
            "wait mode, step: 2\n",
            "Epoch 4/1000\n",
            "18/18 [==============================] - 215s 12s/step - loss: 2.7458 - accuracy: 0.8438 - val_loss: 2.6201 - val_accuracy: 0.8681\n",
            "\n",
            "wait mode, step: 3\n",
            "Epoch 5/1000\n",
            "18/18 [==============================] - 212s 12s/step - loss: 0.9185 - accuracy: 0.9297 - val_loss: 1.8983 - val_accuracy: 0.8750\n",
            "Epoch 6/1000\n",
            "18/18 [==============================] - 212s 12s/step - loss: 0.4232 - accuracy: 0.9448 - val_loss: 1.9591 - val_accuracy: 0.8819\n",
            "\n",
            "wait mode, step: 1\n",
            "Epoch 7/1000\n",
            "18/18 [==============================] - 212s 12s/step - loss: 0.1486 - accuracy: 0.9735 - val_loss: 1.4877 - val_accuracy: 0.8889\n",
            "Epoch 8/1000\n",
            "18/18 [==============================] - 214s 12s/step - loss: 0.1231 - accuracy: 0.9817 - val_loss: 1.4847 - val_accuracy: 0.8889\n",
            "Epoch 9/1000\n",
            "18/18 [==============================] - 215s 12s/step - loss: 0.0366 - accuracy: 0.9901 - val_loss: 1.6193 - val_accuracy: 0.8958\n",
            "\n",
            "wait mode, step: 1\n",
            "Epoch 10/1000\n",
            "18/18 [==============================] - 214s 12s/step - loss: 0.0715 - accuracy: 0.9879 - val_loss: 1.5650 - val_accuracy: 0.8750\n",
            "\n",
            "wait mode, step: 2\n",
            "Epoch 11/1000\n",
            "18/18 [==============================] - 213s 12s/step - loss: 0.0652 - accuracy: 0.9846 - val_loss: 1.5377 - val_accuracy: 0.8958\n",
            "\n",
            "wait mode, step: 3\n",
            "Epoch 12/1000\n",
            "18/18 [==============================] - 213s 12s/step - loss: 0.0554 - accuracy: 0.9870 - val_loss: 1.8531 - val_accuracy: 0.8958\n",
            "\n",
            "wait mode, step: 4\n",
            "Epoch 13/1000\n",
            "18/18 [==============================] - 213s 12s/step - loss: 0.0164 - accuracy: 0.9964 - val_loss: 2.1877 - val_accuracy: 0.9028\n",
            "\n",
            "wait mode, step: 5\n",
            "epoch: 12 : early stopping.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fk1l3F_88lhq"
      },
      "source": [
        "##fine tune "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N7k4FSuL8lhr",
        "outputId": "0da8535e-b7d2-419e-98a4-6746ade51f47"
      },
      "source": [
        "layers = base_model.layers[-50:-1]\n",
        "for layer in layers:\n",
        "  layer.trainable = True\n",
        "model_dense_fine=keras.models.Sequential()\n",
        "model_dense_fine.add(base_model)\n",
        "for i in range(1,len(model_dense.layers)):\n",
        "  model_dense_fine.add(model_dense.layers[i])\n",
        "model_dense_fine.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001), loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),metrics=['accuracy'])\n",
        "model_dense_fine.fit(X_train,y_train,epochs=1000,validation_split=0.2,callbacks=[es_callback])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "18/18 [==============================] - 222s 12s/step - loss: 0.0673 - accuracy: 0.9774 - val_loss: 0.7356 - val_accuracy: 0.8958\n",
            "Epoch 2/1000\n",
            "18/18 [==============================] - 203s 11s/step - loss: 0.0390 - accuracy: 0.9826 - val_loss: 0.6718 - val_accuracy: 0.8819\n",
            "Epoch 3/1000\n",
            "18/18 [==============================] - 205s 11s/step - loss: 0.0398 - accuracy: 0.9809 - val_loss: 0.5746 - val_accuracy: 0.8958\n",
            "Epoch 4/1000\n",
            "18/18 [==============================] - 203s 11s/step - loss: 0.0128 - accuracy: 0.9983 - val_loss: 0.6112 - val_accuracy: 0.8889\n",
            "\n",
            "wait mode, step: 1\n",
            "Epoch 5/1000\n",
            "18/18 [==============================] - 203s 11s/step - loss: 0.0122 - accuracy: 0.9948 - val_loss: 0.5783 - val_accuracy: 0.8958\n",
            "\n",
            "wait mode, step: 2\n",
            "Epoch 6/1000\n",
            "18/18 [==============================] - 203s 11s/step - loss: 0.0142 - accuracy: 0.9913 - val_loss: 0.6056 - val_accuracy: 0.8889\n",
            "\n",
            "wait mode, step: 3\n",
            "Epoch 7/1000\n",
            "18/18 [==============================] - 203s 11s/step - loss: 0.0063 - accuracy: 0.9965 - val_loss: 0.6104 - val_accuracy: 0.8889\n",
            "\n",
            "wait mode, step: 4\n",
            "Epoch 8/1000\n",
            "18/18 [==============================] - 203s 11s/step - loss: 0.0038 - accuracy: 0.9983 - val_loss: 0.6070 - val_accuracy: 0.8889\n",
            "\n",
            "wait mode, step: 5\n",
            "epoch: 7 : early stopping.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f0e9da16490>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n2ywWEFM8lhs",
        "outputId": "acb4ab7c-e3e6-4407-a7b5-a26a35a59a31"
      },
      "source": [
        "prediction_fine_tune_dense=np.argmax(model_dense_fine.predict(X_test),axis=1)\n",
        "print(\"DenseNet Result =====================>>>>\")\n",
        "print('accuracy without fine tuning = '+ str(accuracy_score(y_test,prediction_without_fine_tune_dense)))\n",
        "print('confusion matrix without fine tuning'+ str( confusion_matrix(y_test,prediction_without_fine_tune_dense)))\n",
        "print('accuracy with fine tuning = '+ str(accuracy_score(y_test,prediction_fine_tune_dense)))\n",
        "print('confusion matrix with fine tuning'+ str( confusion_matrix(y_test,prediction_fine_tune_dense)))\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DenseNet Result =====================>>>>\n",
            "accuracy without fine tuning = 0.9375\n",
            "confusion matrix without fine tuning[[39  2]\n",
            " [ 3 36]]\n",
            "accuracy with fine tuning = 0.9375\n",
            "confusion matrix with fine tuning[[40  1]\n",
            " [ 4 35]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8buGCPcIkKP"
      },
      "source": [
        "# **Comparison**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EsU5ETxYImgn",
        "outputId": "c64b283d-e5ba-4030-c236-1db817693517"
      },
      "source": [
        "accuracy_dense = accuracy_score(y_test,prediction_fine_tune_dense)\n",
        "accuracy_res = accuracy_score(y_test,prediction_fine_tune_res)\n",
        "if accuracy_dense> accuracy_res :\n",
        "  print(\"DenseNet Result is better\")\n",
        "else : \n",
        "  print(\"ResNet Result is better\")\n",
        "\n",
        "print(\"============================\")\n",
        "print('accuracy DenseNet = '+ str(accuracy_dense))\n",
        "print('accuracy ResNet = '+ str(accuracy_res))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DenseNet Result is better\n",
            "============================\n",
            "accuracy DenseNet = 0.9375\n",
            "accuracy ResNet = 0.875\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}